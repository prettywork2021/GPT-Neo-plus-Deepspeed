# GPT-Neo-plus-Deepspeed

I have tried to use deepspeed zero offloading (https://www.deepspeed.ai/tutorials/zero-offload/) to run GPT-Neo with small VRAM gpu's. Sadly, it didn't work. Either it is impossible, or i did something wrong. My previous tests, were incorrect. I may try other methods in the future, but for now my solution doesn't work. ¯\\_(ツ)_/¯
